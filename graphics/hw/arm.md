ARM Mali
========

## History

- 2007: Utgard
  - GLES 2.0
  - non-unified, vector isa
  - Mali-{200,300,400,450}
- 2010: Midgard
  - GLES 3.1
  - unified, vector isa
  - 1 to 4 unified shader cores
  - 2 or 4 ALUs per shader core
  - 4x or 16x FSAA
  - 1 MMU
  - 32KB to 256KB L2
  - 16x16 tiles
  - Mali-{T604,T658}
- 2012: Midgard 2nd gen
  - ASTC
  - Mali-{T622,T624,T628,T678}
- 2013: Midgard 3nd gen
  - GLES 3.2
  - 4x to 16x MSAA
  - 256KB to 2048MB L2
  - 1 to 16 cores
  - AFBC framebuffer compression
  - Mali-{T720,T760}
- 2014: Midgard 4nd gen
  - Mali-{T820,T830,T860,T880}
- 2016: Bifrost
  - Unified shaders with quad vectorization
  - Scalar ISA
  - Clauses execution
  - 1 to 32 cores
  - Full cache coherency
  - Mali-{G31,G51,G71}
- 2017: Bifrost 2nd gen
  - Mali-{G52,G72}
- 2018: Bifrost 3nd gen
  - 8 execution lanes per engine (up from 4). Doubled pixel and texel
    throughput.
  - Mali-G76
- 2019: Valhall
  - New superscalar engine
  - Simplified scalar ISA
  - New dynamic scheduling
  - Mali-{G57,G77}
- 2020: Valhall 2nd gen
  - Asynchronous clock domains
  - New FMA units and increase Tiler throughput
  - Arm Frame Buffer Compression (AFBC) 1.3
  - Mali-{G68,G78}
- 2021: Valhall 3rd gen
  - Larger shader cores (2x compared to Valhall 2nd Gen)
  - New GPU frontend, Command Stream Frontend (CSF) replaces the Job Manager (JM)
  - Mali-{G310,G510,G610,G710}
- 2022: Valhall 4th gen
  - Ray Tracing support (hardware-based)
  - Variable Rate Shading
  - New Execution Engine, with doubled the FMA block, Matrix Multiply instruction support, and PPA improvements
  - Arm Fixed Rate Compression (AFRC)
  - Mali-{G615,G715}, Immortalis-G715
- 2023: 5th gen
  - Deferred vertex shading (DVS) pipeline
  - Mali-{G620,G720}, Immortalis-G720
- 2024: 5th gen
  - Mali-{G625,G725}, Immortalis-G925

## Identification

- `GPU_ID` register
  - bit 0..3: status
  - bit 4..11: minor
  - bit 12..15: major
  - bit 16..31: id
    - bit 16..19: product
    - bit 20..23: arch revision
    - bit 24..27: arch minor
    - bit 28..31: arch major
- `pan_arch()`
  - midgard: v4 and v5
    - the 16-bit id is less than `0x1000`
    - a table is used to look up the arch versions
  - bifrost: v6 and v7
    - `id >> 12` is the arch versions
  - valhall: v9 and v10
- kbase uses arch major and product for identification
  - `GPU_ID2_PRODUCT_TMIX` is `GPU_ID2_MODEL_MAKE(6, 0)`
    - mimir?
  - `GPU_ID2_PRODUCT_THEX` is `GPU_ID2_MODEL_MAKE(6, 1)`
    - heimdall?
  - `GPU_ID2_PRODUCT_TSIX` is `GPU_ID2_MODEL_MAKE(7, 0)`
    - sigurd?
  - `GPU_ID2_PRODUCT_TDVX` is `GPU_ID2_MODEL_MAKE(7, 3)`
  - `GPU_ID2_PRODUCT_TNOX` is `GPU_ID2_MODEL_MAKE(7, 1)`
  - `GPU_ID2_PRODUCT_TGOX` is `GPU_ID2_MODEL_MAKE(7, 2)`
  - `GPU_ID2_PRODUCT_TTRX` is `GPU_ID2_MODEL_MAKE(9, 0)`
  - `GPU_ID2_PRODUCT_TNAX` is `GPU_ID2_MODEL_MAKE(9, 1)`
  - `GPU_ID2_PRODUCT_TBEX` is `GPU_ID2_MODEL_MAKE(9, 2)`
  - `GPU_ID2_PRODUCT_TNAX_MT81XX` is `GPU_ID2_MODEL_MAKE(9, 3)`
  - `GPU_ID2_PRODUCT_LBEX` is `GPU_ID2_MODEL_MAKE(9, 4)`
  - `GPU_ID2_PRODUCT_TBAX` is `GPU_ID2_MODEL_MAKE(9, 5)`
  - `GPU_ID2_PRODUCT_TODX` is `GPU_ID2_MODEL_MAKE(10, 2)`
    - valhall 3rd gen, odin?
  - `GPU_ID2_PRODUCT_TGRX` is `GPU_ID2_MODEL_MAKE(10, 3)`
  - `GPU_ID2_PRODUCT_TVAX` is `GPU_ID2_MODEL_MAKE(10, 4)`
  - `GPU_ID2_PRODUCT_LODX` is `GPU_ID2_MODEL_MAKE(10, 7)`
  - `GPU_ID2_PRODUCT_TTUX` is `GPU_ID2_MODEL_MAKE(11, 2)`
    - valhall 4th gen, turse?
  - `GPU_ID2_PRODUCT_LTUX` is `GPU_ID2_MODEL_MAKE(11, 3)`
  - `GPU_ID2_PRODUCT_TTIX` is `GPU_ID2_MODEL_MAKE(12, 0)`
    - 5th gen, titan?
  - `GPU_ID2_PRODUCT_LTIX` is `GPU_ID2_MODEL_MAKE(12, 1)`

## Utgard

- GLES 2.0
- non-unified shader cores
- one vertex core
  - the vertex core and the tiler share a small L2
  - shade one or two vertices serially
  - output to fixed-function tiler for primitive assembly, clipping, cullling,
    and tile list generation
- multiple fragment cores
  - they share a larger L2
  - L2 size is usually `num_cores * 32KB`
  - data flow within a core
    - tile list reader
    - rasterizer
    - early zs tester
    - fragment thread creater
    - threads doing load, texture, arithmetic, and then retire
    - late zs tester
    - blender
    - tile memory
    - tile writeback
  - a core can run up to 128 threads to hide cache misses and memory latency
  - ISA is SIMD and operate on vec4 fp16

## Midgard

- GLES 3.2
- unified shader cores
- a L2 cache shared by all shader cores
  - size is `num_cores * (32KB or 64KB)`
- given a render pass
  - the driver submits geometry workload to HW first
  - the geometry queue block dispatches the workload to shader cores
  - the driver then submits fragment workload to HW
  - the fragment queue block dispatches the workload to shader cores
- a shader core consists of
  - fixed-function part
    - tile list reader
    - rasterizer
    - early zs tester
    - vertex or fragment thread creator
  - programmable tripipe
    - thread pool
    - three types of pipelines
      - one load/store pipeline w/ L1
      - one texture pipeline w/ L1
      - one or more arithmetic pipelines
	- 128-bit SIMD (4 fp32 or 8 fp16 or 16 i8)
    - thread retire
  - more fixed-function parts
    - late zs tester
    - blender
    - tile memory
    - tile writeback
- 16x16 tiles
- 4KB on-chip memory

## Bifrost

- "The Bifrost GPU architecture and the ARM Mali-G71 GPU"
  - by Jem Davies
- a L2 cache shared by all shader cores
  - size is `num_cores * (64KB or 128KB)`
  - full coherency
- up to 32 unified shader cores, where each core consists of
  - a compute frontend
    - quad creator
  - a fragment frontend
    - tile list reader
    - rasterizer
    - early zs tester
    - quad creator
  - a quad manager
    - warp manager
  - up to three execution engines, each
    - 32-bit scalar ISA
    - bifrost uses 4-lane quad-parallel vectorization (SIMT...)
      - a quad is 4 scalar threads executed in lockdep
      - one quad at a time executes in each pipeline stage
      - each thread fills a 32-bit lane of the hardware
      - 4 threads all doing a vec fp32 add take 3 cycles
    - midgard uses 4-lane SIMD vectorization
      - one thread at a time executes in each pipeline stage
      - each thread must fill the width of the hardware
      - 4 threads all doing a SIMD vec3 fp32 add take 4 cycles
  - load/store unit
  - attribute unit
  - varying unit
  - texture units (one or two)
  - zs/blend units (one or two)
    - late zs tester
    - blender
    - tile memory
    - tile writeback
- geometry pipeline
  - instead of 'shade -> assembly -> clip/cull`
  - it does 'assembly -> position shade -> clip/cull -> varying shade`
  - specifically,
    - tiler fetches indices for primitive assembly
    - position shading fetches and transforms only positions
    - tiler clips/culls and stores
      - transformed positions
      - polyton list 
    - varying shading fetches attributes and stores varyings
    - fraghment shading reads back
      - transformed positions
      - polyton list 
      - varyings
  - it is beneficial to have two packed buffers, one for positions and one for
    attributes

## Valhall

- G77 high-level features
  - better AR and ML
  - a new superscalar engine
  - a simplified scalar ISA that is more compiler-friendly
  - dynamic scheduling of instructions
  - data structures that are more Vulkan-friendly
  - 16-wide warps, 32 lanes
    - G76 has 8-wide warps, 24 lanes
  - quad texture mapper, 4 texels/cycle
    - G76 is 2 texels/cycle
  - AFBC 1.3
- a shader core consists of
  - a compute frontend
  - a fragment frontend
  - a manager
  - an execution engine
    - front-end
      - create/retire warps
      - track states for warps
    - scheduler
      - issue instructions
    - two processsing units, each
      - 16-wide FMA unit
      - 16-wide CVT unit (convert unit)
      - 4-wide special function unit
  - an attribute unit
  - a varying unit
  - 4x texture unit
  - a load-store cache
    - replaces the load-store unit

## kbase

- <https://developer.arm.com/downloads/-/mali-drivers/5th-gen-gpu-architecture-kernel>
  - there are separated downloads for
    - Bifrost 3rd Gen GPU Architecture Kernel
    - Valhall 4th Gen GPU Architecture Kernel
    - 5th Gen GPU Architecture Kernel
  - but they are all the same code
- `Kconfig`
  - `MALI_MIDGARD=y`
  - `MALI_PLATFORM_NAME="devicetree"`
  - `MALI_REAL_HW=y`
  - `MALI_CSF_SUPPORT=y`
  - `MALI_DEVFREQ=y`
  - `LARGE_PAGE_SUPPORT=y`
  - `PAGE_MIGRATION_SUPPORT=y`
- `Kbuild`
  - `Makefile` is preferred, but if `Kbuild` exists, it is used
  - the top-level `Kbuild` includes the subdir `Kbuild`s
  - `CONFIG_MALI_CSF_SUPPORT` causes different files to be compiled

## kbase init

- `kbase_driver_init` registers `kbase_platform_driver`
  - driver name is `mali`
  - id table has `arm,mali-valhall`, `arm,mali-bifrost`, etc.
- `kbase_device_init` initializes the device
  - `kbase_get_irqs`
    - `platform_get_irq_byname` gets 3 IRQs: `JOB`, `MMU`, and `GPU`
  - `registers_map`
    - `platform_get_resource` gets `IORESOURCE_MEM`
    - `kbase_common_reg_map` requests and ioremaps the region
  - `power_control_init` gets the regulators and clks
  - `kbase_device_io_history_init` inits `kbdev->io_history`
  - `kbase_device_early_init`
    - `kbasep_platform_device_init` depends on `MALI_PLATFORM_NAME`
    - `kbase_pm_runtime_init` depends on `MALI_PLATFORM_NAME`
    - `kbase_gpuprops_parse_gpu_id` reads and parses `GPU_ID` reg
    - `kbase_regmap_init` inits `kbdev->regmap`
    - `kbase_hw_set_features_mask` inits `kbdev->hw_features_mask` based on
      `GPU_ID`
    - `kbase_gpuprops_init` reads various regs to init `kbdev->gpu_props`
      - `SHADER_PRESENT`, `TILER_PRESENT`, `L2_PRESENT`, etc.
    - `kbase_hw_set_issues_mask` inits hw workarounds
    - `kbase_install_interrupts` registers irq handlers
      - `kbase_job_irq_handler`
      - `kbase_mmu_irq_handler`
      - `kbase_gpu_irq_handler`
  - `kbase_backend_time_init` inits `kbdev->backend_time`
  - `kbase_device_misc_init` inits various stuff
  - `kbase_device_pcm_dev_init`
  - `kbase_ctx_sched_init`
  - `kbase_mem_init`
  - `kbase_csf_protected_memory_init`
  - `kbase_device_coherency_init` inits `kbdev->system_coherency`
    - usually to `COHERENCY_NONE`
  - `kbase_protected_mode_init`
  - `kbase_device_list_init`
  - `kbase_device_timeline_init` inits `kbdev->timeline`
  - `kbase_clk_rate_trace_manager_init`
  - `kbase_device_hwcnt_watchdog_if_init`
  - `kbase_device_hwcnt_backend_csf_if_init`
  - `kbase_device_hwcnt_backend_csf_init`
  - `kbase_device_hwcnt_context_init`
  - `kbase_csf_early_init` inits `kbdev->csf`
  - `kbase_backend_late_init`
  - `kbase_csf_late_init`
  - `kbase_debug_csf_fault_init`
  - `kbase_device_debugfs_init`
  - `kbase_csf_fence_timer_debugfs_init`
  - `kbase_sysfs_init` inits `kbdev->mdev` and sysfs
  - `kbase_device_misc_register` registers `kbdev->mdev`
  - `kbase_gpuprops_populate_user_buffer` inits gpu props to be queried by
    userspace
  - `kbase_device_late_init`
- when `/dev/mali0` is opened, `kbase_open` is called
  - `kbase_device_firmware_init_once` loads `mali_csffw.bin`
  - `kbase_file_new` creates a `kbase_file`

## kbase ioctls

- ioctls are handled by `kbase_ioctl`
- `KBASE_IOCTL_VERSION_CHECK` is handled by `kbase_api_handshake`
  - it negotiates uapi version
- `KBASE_IOCTL_SET_FLAGS` is handled by `kbase_api_set_flags`
  - `kbase_file_create_kctx` creates the ctx
- `KBASE_IOCTL_KINSTR_PRFCNT_ENUM_INFO` is handled by `kbase_api_kinstr_prfcnt_enum_info`
- `KBASE_IOCTL_KINSTR_PRFCNT_SETUP` is handled by `kbase_api_kinstr_prfcnt_setup`
- `KBASE_IOCTL_GET_GPUPROPS` is handled by `kbase_api_get_gpuprops`
  - queries all gpu props
- `KBASE_IOCTL_MEM_ALLOC` is handled by `kbase_api_mem_alloc`
  - it calls `kbase_api_mem_alloc_ex`
  - it returns `gpu_va` to the userspace, which is also used as the handle to
    the bo
  - `kbase_region_tracker_find_region_base_address` maps `gpu_va` to
    `kbase_va_region`
- `KBASE_IOCTL_MEM_QUERY` is handled by `kbase_api_mem_query`
- `KBASE_IOCTL_MEM_FREE` is handled by `kbase_api_mem_free`
- `KBASE_IOCTL_DISJOINT_QUERY` is handled by `kbase_api_disjoint_query`
- `KBASE_IOCTL_GET_DDK_VERSION` is handled by `kbase_api_get_ddk_version`
  - it returns the DDK version string, such as `K:r51p0-00eac0(GPL)`
- `KBASE_IOCTL_MEM_JIT_INIT` is handled by `kbase_api_mem_jit_init`
- `KBASE_IOCTL_MEM_EXEC_INIT` is handled by `kbase_api_mem_exec_init`
- `KBASE_IOCTL_MEM_SYNC` is handled by `kbase_api_mem_sync`
- `KBASE_IOCTL_MEM_FIND_CPU_OFFSET` is handled by `kbase_api_mem_find_cpu_offset`
- `KBASE_IOCTL_MEM_FIND_GPU_START_AND_OFFSET` is handled by `kbase_api_mem_find_gpu_start_and_offset`
- `KBASE_IOCTL_GET_CONTEXT_ID` is handled by `kbase_api_get_context_id`
- `KBASE_IOCTL_TLSTREAM_ACQUIRE` is handled by `kbase_api_tlstream_acquire`
- `KBASE_IOCTL_TLSTREAM_FLUSH` is handled by `kbase_api_tlstream_flush`
- `KBASE_IOCTL_MEM_COMMIT` is handled by `kbase_api_mem_commit`
- `KBASE_IOCTL_MEM_ALIAS` is handled by `kbase_api_mem_alias`
- `KBASE_IOCTL_MEM_IMPORT` is handled by `kbase_api_mem_import`
- `KBASE_IOCTL_MEM_FLAGS_CHANGE` is handled by `kbase_api_mem_flags_change`
- `KBASE_IOCTL_MEM_PROFILE_ADD` is handled by `kbase_api_mem_profile_add`
- `KBASE_IOCTL_STICKY_RESOURCE_MAP` is handled by `kbase_api_sticky_resource_map`
- `KBASE_IOCTL_STICKY_RESOURCE_UNMAP` is handled by `kbase_api_sticky_resource_unmap`
- `KBASE_IOCTL_GET_CPU_GPU_TIMEINFO` is handled by `kbase_api_get_cpu_gpu_timeinfo`
  - returns `CYCLE_COUNT`, `TIMESTAMP`, and `ktime_get_raw_ts64`
- `KBASE_IOCTL_CONTEXT_PRIORITY_CHECK` is handled by `kbasep_ioctl_context_priority_check`
  - it updates ctx priority
- `KBASE_IOCTL_SET_LIMITED_CORE_COUNT` is handled by `kbase_ioctl_set_limited_core_count`
  - it updates `kctx->limited_core_mask`
- `MALI_USE_CSF`
  - `KBASE_IOCTL_MEM_ALLOC_EX` is handled by `kbase_api_mem_alloc_ex`
  - `KBASE_IOCTL_CS_EVENT_SIGNAL` is handled by `kbasep_cs_event_signal`
  - `KBASE_IOCTL_CS_QUEUE_REGISTER` is handled by `kbasep_cs_queue_register`
    - registers a mem as a queue and creates `kbase_queue` for it
  - `KBASE_IOCTL_CS_QUEUE_REGISTER_EX` is handled by `kbasep_cs_queue_register_ex`
  - `KBASE_IOCTL_CS_QUEUE_TERMINATE` is handled by `kbasep_cs_queue_terminate`
  - `KBASE_IOCTL_CS_QUEUE_BIND` is handled by `kbasep_cs_queue_bind`
    - adds a queue to a queue group
  - `KBASE_IOCTL_CS_QUEUE_KICK` is handled by `kbasep_cs_queue_kick`
  - `KBASE_IOCTL_CS_QUEUE_GROUP_CREATE` is handled by `kbasep_cs_queue_group_create`
    - creates a `kbase_queue_group`
  - `KBASE_IOCTL_CS_QUEUE_GROUP_TERMINATE` is handled by `kbasep_cs_queue_group_terminate`
  - `KBASE_IOCTL_KCPU_QUEUE_CREATE` is handled by `kbasep_kcpu_queue_new`
    - creates a `kbase_kcpu_command_queue`
  - `KBASE_IOCTL_KCPU_QUEUE_DELETE` is handled by `kbasep_kcpu_queue_delete`
  - `KBASE_IOCTL_KCPU_QUEUE_ENQUEUE` is handled by `kbasep_kcpu_queue_enqueue`
  - `KBASE_IOCTL_QUEUE_GROUP_CLEAR_FAULTS` is handled by `kbasep_queue_group_clear_faults`
  - `KBASE_IOCTL_CS_TILER_HEAP_INIT` is handled by `kbasep_cs_tiler_heap_init`
  - `KBASE_IOCTL_CS_TILER_HEAP_TERM` is handled by `kbasep_cs_tiler_heap_term`
  - `KBASE_IOCTL_CS_GET_GLB_IFACE` is handled by `kbase_ioctl_cs_get_glb_iface`
  - `KBASE_IOCTL_CS_CPU_QUEUE_DUMP` is handled by `kbasep_ioctl_cs_cpu_queue_dump`
  - `KBASE_IOCTL_READ_USER_PAGE` is handled by `kbase_ioctl_read_user_page`
- `!MALI_USE_CSF`
  - `KBASE_IOCTL_JOB_SUBMIT` is handled by `kbase_api_job_submit`
  - `KBASE_IOCTL_POST_TERM` is handled by `kbase_api_post_term`
  - `KBASE_IOCTL_SOFT_EVENT_UPDATE` is handled by `kbase_api_soft_event_update`
  - `KBASE_IOCTL_KINSTR_JM_FD` is handled by `kbase_api_kinstr_jm_fd`
- `CONFIG_SYNC_FILE`
  - `KBASE_IOCTL_STREAM_CREATE` is handled by `kbase_api_stream_create`
    - returns an fd
  - `KBASE_IOCTL_FENCE_VALIDATE` is handled by `kbase_api_fence_validate`
- `CONFIG_MALI_CINSTR_GWT`
  - `KBASE_IOCTL_CINSTR_GWT_START` is handled by `kbase_gpu_gwt_start`
  - `KBASE_IOCTL_CINSTR_GWT_STOP` is handled by `kbase_gpu_gwt_stop`
  - `KBASE_IOCTL_CINSTR_GWT_DUMP` is handled by `kbase_gpu_gwt_dump`
