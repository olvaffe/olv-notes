Mesa PanVK
==========

## Meson

- `panvk_entrypoints` generates
  - `panvk_instance_entrypoints`
  - `panvk_physical_device_entrypoints`
  - `panvk_device_entrypoints`
  - `panvk_v6_device_entrypoints`
  - `panvk_v7_device_entrypoints`
  - `panvk_v9_device_entrypoints`
  - `panvk_v10_device_entrypoints`
  - the idea is that, for device entrypoints, it dispatches to `vk_vX_Foo` if
    defined and falls back to `vk_Foo` if not
- `panvk_per_arch_libs` are per-arch static libraries
  - the source files are
    - `common_per_arch_files` (`panvk_vX_*.c`)
    - `bifrost_files` (`bifrost/*.c`) if v7 or older
    - `valhall_files` (`valhall/*.c`) if v9 or newer
    - `jm_files` (`jm/*.c`) if v9 or older
    - `csf_files` (`csf/*.c`) if v10+
  - `PAN_ARCH` is defined per-arch
- `libvulkan_panfrost` is the final shared library
  - `libpanvk_files` consists of non-per-arch `panvk_*.c`
- depenencies
  - `idep_pan_packers`, packet packers generated by genxml
  - `libpanfrost_shared`, helpers shared between panvk, panfrost, and lima
  - `libpanfrost_midgard`, midgard (v5 or older) compiler
  - `libpanfrost_bifrost`, bifrost (v6 or newer) compiler
  - `libpanfrost_decode`, packet decoder generated by genxml
  - `libpanfrost_lib`, helpers shared between panvk and panfrost
  - `libpanfrost_util`, helpers shared between bifrost and midgard compilers

## Environment Variables

- `PAN_I_WANT_A_BROKEN_VULKAN_DRIVER` is required to use panvk
- `PANVK_DEBUG` is parsed by `panvk_debug_options`
  - `startup` prints init info
  - `nir` dumps lowered nir before passing it to the backend compiler
  - `sync` waits for all submits
  - `trace` implies `sync` and dumps all submits
  - `afbc` allows AFBC
  - `linear` forces linear tiling
  - `dump` dumps vk memory contents on submits
  - `no_known_warn` is JM (job manager) only
- `PANDECODE_DUMP_FILE` defaults to `pandecode.dump`
- `BIFROST_MESA_DEBUG` is for the bifrost compiler
- `MIDGARD_MESA_DEBUG` is for the midgard compiler
- drm-shim
  - `VK_DRIVER_FILES=panfrost_icd.x86_64.json`
  - `LD_PRELOAD=libpanfrost_noop_drm_shim.so`
  - `PAN_I_WANT_A_BROKEN_VULKAN_DRIVER=1`
  - `PAN_GPU_ID=0xABCD`
  - no panthor

## `pan_kmod_ops`

- `panthor_kmod_dev_create`
  - each `panvk_physical_device` and each `panvk_device` own a `pan_kmod_dev`
  - `DRM_IOCTL_PANTHOR_DEV_QUERY`
- `panthor_kmod_dev_destroy`
- `panthor_dev_query_props`
- `panthor_kmod_dev_query_user_va_range`
  - `panvk_device` uses this to decide the user va region
- `panthor_kmod_bo_alloc`
  - each `panvk_queue` has a bo as the ring buffer
  - `panvk_priv_bo_create` calls this for panvk-internal bos
  - each `panvk_device_memory` has a bo, either allocated or imported
  - `DRM_IOCTL_PANTHOR_BO_CREATE`
- `panthor_kmod_bo_free`
- `panthor_kmod_bo_import`
- `panthor_kmod_bo_export`
- `panthor_kmod_bo_get_mmap_offset`
  - `DRM_IOCTL_PANTHOR_BO_MMAP_OFFSET`
- `panthor_kmod_bo_wait`
  - panvk does not need this
- `panthor_kmod_vm_create`
  - each `panvk_device` has a vm
  - `DRM_IOCTL_PANTHOR_VM_CREATE`
- `panthor_kmod_vm_destroy`
  - `DRM_IOCTL_PANTHOR_VM_DESTROY`
- `panthor_kmod_vm_bind`
  - all bos must be bound to a device vm before they can be accessed by hw
  - `DRM_IOCTL_PANTHOR_VM_BIND`
- `panthor_kmod_vm_query_state`
  - panvk does not use this yet; query for faulty vm
  - `DRM_IOCTL_PANTHOR_VM_GET_STATE`
- `panthor_kmod_query_timestamp`
  - `DRM_IOCTL_PANTHOR_DEV_QUERY`
- some ioctls are not abstracted
- `panvk_per_arch(queue_init)`
  - `DRM_IOCTL_PANTHOR_TILER_HEAP_CREATE`
  - `DRM_IOCTL_PANTHOR_GROUP_CREATE`
    - `drm_panthor_group_create`
      - it can control which cores a draw or a dispatch runs on
      - `priority` decides the priority
      - `queues` uses 3 queues
        - `PANVK_SUBQUEUE_VERTEX_TILER`
        - `PANVK_SUBQUEUE_FRAGMENT`
        - `PANVK_SUBQUEUE_COMPUTE`
- `panvk_per_arch(queue_finish)`
  - `DRM_IOCTL_PANTHOR_GROUP_DESTROY`
  - `DRM_IOCTL_PANTHOR_TILER_HEAP_DESTROY`
- `panvk_queue_submit`
  - `DRM_IOCTL_PANTHOR_GROUP_SUBMIT`
- query device lost
  - `DRM_IOCTL_PANTHOR_GROUP_GET_STATE`

## BO and Address Space

- `pan_kmod_bo_alloc` makes the `DRM_IOCTL_PANTHOR_BO_CREATE` ioctl
  - there are only 3 callers
  - `init_queue` allocs a ringbuf for
    `VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT`
  - `panvk_AllocateMemory` allocs a bo for user device memory
  - `panvk_priv_bo_create` allocs a bo for driver use, which in turn have
    these callers
    - `panvk_pool_alloc_backing` allocs a bo for a mempool
    - `panvk_per_arch(CreateDescriptorPool)` allocs a bo for descs
    - `panvk_per_arch(create_device)` allocs a bo for sample pos
- `pan_kmod_vm_bind` makes the `DRM_IOCTL_PANTHOR_VM_BIND`
  - this has the same callers as `pan_kmod_bo_alloc` does at the moment, plus
    unmaps on destroy
  - because `PAN_KMOD_VM_FLAG_AUTO_VA` is not set when creating
    `dev->kmod.vm`, all vmas are allocated from
    `util_vma_heap_alloc(&dev->as.heap)`
- `panvk_per_arch(create_device)` inits the vm
  - `user_va_start` is 32MB
  - `user_va_end` is 4GB
  - `device->as.heap` manages `[user_va_start, user_va_end)`
    - by default, `util_vma_heap` allocs from the top
    - with 4GB AS, bos start from `0xffffffff` and grow down
  - `device->kmod.vm` is created with the same range
    - `vm_flags` does not include `PAN_KMOD_VM_FLAG_AUTO_VA`
      - if it did, kmod would init a `util_vma_heap` the same way
    - hw reports `mmu_features`
      - typically, there are 40 pa bits and 48 va bits
      - the 48 va space is shared by usersapce (bottom) and kernel space (top)
      - because panvk asks for 4GB, the first 4GB is reserved for userspace
        and the kernel uses the rest
      - `panthor_vm_create_check_args` wants the start addr to be
        power-of-two and ends up with `1ull << 47`
      - `drm_mm` with `DRM_MM_INSERT_BEST` allocs from the bottom
      - bos thus start from `0x800000000000` and grows up

## Queue

- `panvk_per_arch(queue_init)`
  - `drmSyncobjCreate` creates a syncobj
    - `queue->syncobj_handle` is used for semaphore signals
  - `init_tiler`
    - `tiler_heap->context` is from `DRM_IOCTL_PANTHOR_TILER_HEAP_CREATE`
    - `tiler_heap->desc` is a bo of size 4KB plus 64KB
      - the first 4KB is for `MALI_TILER_HEAP` descriptor
      - the rest 64KB is for geometry buffer
  - `create_group`
    - `queue->group_handle` is from `DRM_IOCTL_PANTHOR_GROUP_CREATE`
    - there are 3 sub-queues
      - `PANVK_SUBQUEUE_VERTEX_TILER`
      - `PANVK_SUBQUEUE_FRAGMENT`
      - `PANVK_SUBQUEUE_COMPUTE`
  - `init_queue`
    - `queue->syncobjs` is an array of per-subqueue `panvk_cs_sync64`
      - this is to track the per-subqueue seqno
    - `init_render_desc_ringbuf` inits `queue->render_desc_ringbuf`
      - this is used only for `VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT`
      - `ringbuf->bo` is `RENDER_DESC_RINGBUF_SIZE` (512KB)
      - `ringbuf->bo` is vm-bound twice consecutively
        - this simplifies wrap-around handling
      - `ringbuf->syncobj` is a `panvk_cs_sync32`
    - `init_subqueue` inits each of `queue->subqueues`
      - `subq->context` is a bo for `panvk_cs_subqueue_context`
        - it is only accessed by hw after initialization
        - `syncobjs` points to `queue->syncobjs` and `syncobjs[subq]` is
          initialized to 1
        - `iter_sb` is initialized to 0
        - `render` is not used by `PANVK_SUBQUEUE_COMPUTE`
          - `tiler_heap` points to `queue->tiler_heap.desc`
          - `geom_buf` points to `queue->tiler_heap.desc + 4KB`
          - `desc_ringbuf` points to `queue->render_desc_ringbuf`
      - first submit to init the subqueue
        - this abuses the geom buf as cs root chunk
        - `MOV64 cs_subqueue_ctx_reg(), subq->context` inits the subq ctx reg
        - `SET_SB_ENTRY` such that ep tasks (frag & comp) use `SB_ITER(0)`
          (slot 3) and other tasks (tiler) uses `SB_ID(LS)` (slot 0)
          - this matches `iter_sb` in subq ctx
        - if not `PANVK_SUBQUEUE_COMPUTE`, inits the tiler heap as well
          - `MOV64 scratch0, queue->tiler_heap.context.dev_addr`
          - `HEAP_SET scratch0`
- `panvk_queue_submit`
  - if there are semaphore waits
    - sets up a `drm_panthor_sync_op` with `DRM_PANTHOR_SYNC_OP_WAIT` for each
      wait
    - sets up an empty `drm_panthor_queue_submit` for each used subqueue to
      wait on the `drm_panthor_sync_op` array above
  - for each cmdbufs
    - sets up a `drm_panthor_queue_submit` for each used subqueue
  - if there are semaphore signals
    - for each used subqueue, sets up a `drm_panthor_sync_op` with
      `DRM_PANTHOR_SYNC_OP_SIGNAL` and sets up an empty
      `drm_panthor_queue_submit`
    - they all signal `queue->syncobj_handle`
    - the fence is then copied to user semaphores using `drmSyncobjTransfer`
    - `queue->syncobj_handle` is reset

## Command Stream

- `genxml/v10.xml`
  - CS aka CEU (Command Execution Unit)
  - 7 cs enums
    - `CS Condition`
    - `CS State`
    - `CS Heap Operation`
    - `CS Flush Mode`
    - `CS Sync scope`
    - `CS Exception type`
    - `CS Opcode`
  - 40 cs structs
    - `pandecode_cs` is a good place to know how they work
      - `interpret_ceu_instr`
      - `disassemble_ceu_instr`
    - all structs have size 2 (dwords)
    - `CS Base` is not a real opcode
      - it is only used by the decoder
      - bit 0..55: op payload
      - bit 56..63: op code
    - `CS NOP` is nop
      - the payload is ignored
    - `CS MOVE` does `dst_reg = imm48`
    - `CS MOVE32` does `dst_reg = imm32`
    - `CS WAIT` waits the specified slots (scoreboards?)
      - the fw supports `scoreboard_slot_count` slots
      - userspace can decide which is for what
      - `PANVK_SB_LS`, load/store
      - `PANVK_SB_IMM_FLUSH`,
      - `PANVK_SB_DEFERRED_SYNC`
      - `PANVK_SB_DEFERRED_FLUSH`
      - `PANVK_SB_ITER_START`
      - `PANVK_SB_ITER_COUNT`
    - `CS RUN_COMPUTE` runs a compute job
      - it expects reg0..reg39 to be set up, such as
        - reg0 points to res table
        - reg8 points to push consts
        - reg16 points to shader
        - reg24 points to local storage
        - reg32 is global attr offset
        - reg33 is wg size
        - reg34..36 are wg offsets
        - reg37..39 are wg counts
    - `CS RUN_TILING` runs a tiling job, unused?
    - `CS RUN_IDVS` runs an idvs (index-driven vs) job
      - traditional vs: vertex shading -> primitive assembly -> culling
        - wasted computation if a primitive is culled
      - idvs since bifrost: primitive assembly -> position shading -> culling -> varying shading
    - `CS RUN_FRAGMENT` runs an fs job
    - `CS RUN_FULLSCREEN` runs a fullscreen job
    - `CS FINISH_TILING`
    - `CS FINISH_FRAGMENT`
    - `CS ADD_IMMEDIATE32` does `dst_reg = src_reg + imm32`
    - `CS ADD_IMMEDIATE64` does `dst_reg64 = src_reg64 + imm32`
    - `CS UMIN32` does `dst_reg = min(src_reg1, src_reg2)`
    - `CS LOAD_MULTIPLE` does `dst_reg = load(src_reg + imm16)`
    - `CS STORE_MULTIPLE` does `store(src_reg1 + imm16, src_reg2)`
    - `CS BRANCH` jumps a signed imm16 offset if the reg meets the condition
    - `CS SET_SB_ENTRY` selects the scoreboard slots for endpoint tasks (frag
      & comp) and other tasks (tiler)
    - `CS PROGRESS_WAIT` is unused
    - `CS SET_EXCEPTION_HANDLER` is unused
    - `CS CALL` calls `(reg1, reg2)`
      - `reg1` is the addr
      - `reg2` is the length
    - `CS JUMP` jumps to `(reg1, reg2)`
      - why does it need the length?
    - `CS REQ_RESOURCE` is needed before/after running a job
      - it requests and releases the needed res?
    - `CS FLUSH_CACHE2` flushes L2 and LSC caches
      - this is used for barriers
    - `CS SYNC_ADD32`  does `store(addr, load(addr) + src_reg)` after sync
    - `CS SYNC_SET32` does `store(addr, src_reg)` after sync
    - `CS SYNC_WAIT32` busy-waits until an `load(addr)` meets the condition
    - `CS STORE_STATE` does `store(src_reg + imm16, state)`, where `state` is
      - `MALI_CS_STATE_TIMESTAMP`
      - `MALI_CS_STATE_CYCLE_COUNT`
      - `MALI_CS_STATE_DISJOINT_COUNT`
      - `MALI_CS_STATE_ERROR_STATUS`
    - `CS PROT_REGION` is unused
    - `CS PROGRESS_STORE` is unused
    - `CS PROGRESS_LOAD` is unused
    - `CS RUN_COMPUTE_INDIRECT` runs a compute job
    - `CS ERROR_BARRIER` is unused
    - `CS HEAP_SET` sets the heap va
    - `CS HEAP_OPERATION`
    - `CS TRACE_POINT` is unused
    - `CS SYNC_ADD64`
    - `CS SYNC_SET64`
    - `CS SYNC_WAIT64`
- `cs_builder`
  - `cs_builder_conf`
    - `nr_registers` is the number of regs and is arch-dependent
    - `nr_kernel_registers` is the number of regs at the top that the kmd uses
      - `cs_builder` itself also uses the top 3 regs for chunk linking
    - `alloc_buffer` allocates a new bo for instrs
    - `ls_tracker` validates loads/stores and is for debugging
    - `reg_perm` validates reg accesses and is for debugging
  - a `cs_chunk` is a BO
    - multiple chunks are linked together by `JUMP` instr
    - `root_chunk` is the first BO
    - `cur_chunk` is the current BO
  - `blocks` is for control flow
    - `stack` is the current cfg node, if non-null
    - `instrs` is a temporary storage for instrs belonging to a control flow
      - this is done to avoid chunk linking in the middle of a control flow
    - `pending_if`
  - `length_patch` is for chunk linking
    - `JUMP` requires a va and a length, but the length of the next chunk is
      unkonwn yet
    - `length_patch` points to the length field, which will be patched in when
      the size of the next chunk is known
  - `discard_instr_slot` is used only when bo allocation fails
- `cs_alloc_ins_block` returns a pointer to a u64 for the next instr(s)
  - if `b->blocks.stack` is non-NULL, we are in a control flow and instrs are
    stashed to `b->blocks.instrs` temporarily
    - `cs_flush_block_instrs` will copy them to the current chunk
  - if `b->cur_chunk` is full,
    - allocates a new bo
    - sets up a jump to the new bo from the current bo
      - `cs_overflow_address_reg` and `cs_overflow_length_reg` use the top 3
        regs
    - `cs_wrap_chunk` ends the current chunk
    - `b->length_patch` is set up (which will be patched to the len of the new
      chunk)
    - `b->cur_chunk` is updated
  - increments `b->cur_chunk` and returns a ptr in `b->cur_chunk`
- `cs_scratch_reg32` returns a `cs_index`
  - it checks that the reg is in `PANVK_CS_REG_SCRATCH_{START,END}`
  - `cs_reg_tuple` builds the `cs_index` struct
  - there is a total of `b->conf.nr_registers - b->conf.nr_kernel_registers`
    registers
- `cs_move32_to`
  - `cs_alloc_ins` returns a ptr to an instr
    - the ptr points to an offset in `b->cur_chunk.buffer.cpu` which is u64
  - `pan_pack` expands to
    - `struct MALI_CS_MOVE32 I = { MALI_CS_MOVE32_header }`
    - custom code to modify `I`
    - `MALI_CS_MOVE32_pack(ptr, &I)`
  - `cs_dst32` converts a `cs_index` into a u8, the raw reg number
- `cs_branch` skips offset if `cond(val)` is true
- control flow
  - `cs_block_start` and `cs_block_end` start/end a cfg node
    - they update `b->blocks.stack`
  - `cs_while(MALI_CS_CONDITION_ALWAYS)`
    - `cs_while_start`
      - `cs_block_start` adds a block
      - `cs_set_label(b, &loop->start)` updates `loop->start` to target start
        of block
    - `cs_while_end`
      - `cs_branch_label(b, &loop->start, ...)` emits `BRANCH` instr to jump
        back to the start of block if `cond(val)` is true
      - `cs_set_label(b, &loop->end)` updates `loop->end` to target end of
        block
        - if `cs_break` was used, it also patches all `BREAK` instrs
      - `cs_block_end` ends the block
        - `cs_flush_block_instrs` copies stashed cfg node instrs into the
          current chunk
    - if there is `cs_continue`, `cs_loop_conditional_continue` calls
      `cs_branch_label(b, &loop->start, ...)` to `BRANCH` backward to the start
    - if there is `cs_break`, `cs_loop_conditional_break` calls
      `cs_branch_label(b, &loop->end, ...)` to `BRANCH` forward to the end
      - because the location of the end is unknown, we save the location of
        the `BRANCH` in `last_forward_ref` for later patching
      - if there are multiple breaks, we use the `offset` field of `BRANCH`
        instrs to form a list
  - `cs_match`
    - `cs_match_start`
      - `cs_block_start`
    - `cs_case(N)`
      - if there is a prior `cs_case(M)`
        - it calls `cs_branch_label(b, &match->break_label, ...)` to jump to
          the end for the prior case
          - that is, if the prior case is a match, it jumps to the end
        - it calls `cs_set_label(b, &match->next_case_label)` to point
          `next_case_label` to the start for the current case
          - that is, if the prior case is not a match, it jumps to this case
        - it reinitializes `next_case_label`
      - it calls `cs_branch_label(b, &match->next_case_label, ...)` with the
        condition `(val - N) != 0`
        - that is, it jumps to the next case if `val` is not N
    - `cs_default`
      - it calls `cs_branch_label(b, &match->break_label, ...)` to jump to the
        end for the prior case
        - that is, if the prior case is a match, it jumps to the end
      - it calls `cs_set_label(b, &match->next_case_label)`
        - that is, if the prior case is not a match, it jumps to the this
          defualt case
      - it reinitializes `next_case_label`
    - `cs_match_end`
      - `cs_set_label` is called on both `next_case_label` and `break_label`
      - `cs_block_end`
  - `cs_if`
    - `cs_if_start`
      - `cs_block_start` adds a block
      - `cs_branch_label` branches forward to the end if `!cond(val)`
    - `cs_if_end`
      - rather than calling `cs_block_end`, it saves the block to
        `b->blocks.pending_if`
      - later, `cs_flush_pending_if` will update `b->blocks.stack`
      - this is done such that `cs_else` has a chance to patch `cs_if`?
- panvk-specific helpers
  - `panvk_cs_reg_whitelist` is a macro to define a `reg_perm_cb_t`
    - it validates that the regs being written are on the whitelist
  - `cs_update_progress_seqno(b) { foo }` validates that foo only writes to
    seqno regs (84..89)
    - 2 regs per subqueue
    - `PANVK_SUBQUEUE_VERTEX_TILER` uses 84 and 85
    - `PANVK_SUBQUEUE_FRAGMENT` uses 86 and 87
    - `PANVK_SUBQUEUE_COMPUTE` uses 88 and 89
  - `cs_update_compute_ctx(b) { foo }` validates that foo only writes to
    compute regs (0..39)
  - `cs_update_frag_ctx(b) { foo }` validates that foo only writes to
    frag regs (40..46)
  - `cs_update_vt_ctx(b) { foo }` validates that foo only writes to
    vertex tiler / idvs regs (0..60)

## Command Stream Decoder

- usage
  - `pandecode_create_context` and `pandecode_destroy_context` are called
    per-VkDevice
  - `pandecode_inject_mmap` and `pandecode_inject_free` are called per-BO
    - `ctx->mmap_tree` manages the BOs
  - these are called per-queue-submit
    - `pandecode_dump_file_open` opens the file
      - optional because `pandecode_cs` and `pandecode_dump_mappings` (but not
        `pandecode_log`) open on-demand
    - `pandecode_log` printfs to the file
    - `pandecode_cs` decodes a command stream
    - `pandecode_dump_mappings` dumps the contents of BOs
    - `pandecode_next_frame` closes the file
- `pandecode_cs` calls `GENX(pandecode_cs)`
  - `regs` is an array of 256 u32, initialized to 0, on stack
  - `pandecode_find_mapped_gpu_mem_containing` finds the BO containing the cs
    - it also `mprotect` the BO and adds it to `ctx->ro_mappings`
    - at the end of decode, `pandecode_map_read_write` undoes the `mprotect`
  - `disassemble_ceu_instr` prints the u64 instr
  - `interpret_ceu_instr` simulates the u64 instr
- `pandecode_run_idvs` decodes `RUN_IDVS`
  - `d0`, `d2`, and `d4` are SRT
    - vs may be separated into position shader and varying shader
    - position shader always uses `d0`
    - varying shader uses `d0` or `d2`, depending on a bit of the instr
    - fragment shader uses `d0` or `d4`, depending on a bit of the instr
    - `GENX(pandecode_resource_tables)` decodes SRT
  - `d8`, `d10`, and `d12` are FAU
    - position shader always uses `d8`
    - varying shader uses `d8` or `d10`, depending on a bit of the instr
    - fragment shader always uses `d12`
    - `GENX(pandecode_fau)` decodes FAU
  - `d16`, `d18`, and `d20` are SPD (shader program descriptor?)
    - position shader always uses `d16`
    - varying shader always uses `d18`, if separated from position shader
    - fragment shader always uses `d20`
    - `GENX(pandecode_shader)` decodes SPD
  - `d24`, `d26`, and `d28` are TSD
    - position shader always uses `d24`
    - varying shader uses `d24` or `d26`, depending on a bit of the instr
    - fragment shader uses `d24` or `d28`, depending on a bit of the instr
  - `r32` is `Global attribute offset`
  - `r33` is `Index count`
  - `r34` is `Instance count`
  - `r35` is `Index offset`
  - `r36` is `Vertex offset`
  - `r37` is `Instance offset`
  - `r38` is `Tiler DCD flags2`
  - `r39` is `Index array size`
  - `d40` is tiler context
    - `GENX(pandecode_tiler)` decodes tiler context
  - `d42` is `Scissor`
  - `r44` is `Low depth clamp`
  - `r45` is `High depth clamp`
  - `d46` is `Occlusion`
  - `d48` is `Varying allocation`
  - `d50` is `Blend`
    - `GENX(pandecode_blend_descs)` decodes blend
  - `d52` is `Depth/stencil`
  - `d54` is `Indices`
  - `d56` is `Primitive flags`
  - `r57` is `DCD Flags 0`
  - `r58` is `DCD Flags 1`
  - `r60` is `Primitive size`
- `pandecode_run_fragment` decodes `RUN_FRAGMENT`
  - `d40` is FBD (framebuffer descriptor?)
    - `GENX(pandecode_fbd)` decodes FBD
  - `d42` is `Scissor`
- `pandecode_run_compute` decodes `RUN_COMPUTE`
  - `d0`, `d2`, `d4`, `d6` are SRT (resource table)
    - the instr selects one of them
    - `GENX(pandecode_resource_tables)` decodes SRC
  - `d8`, `d10`, `d12`, `d14` are FAU (fast access uniform, aka push consts)
    - the instr selects one of them
    - `GENX(pandecode_fau)` decodes FAU
  - `d16`, `d18`, `d20`, `d22` are SPD (shader)
    - the instr selects one of them
    - `GENX(pandecode_shader)` decodes SPD
  - `d24`, `d26`, `d28`, `d30` are TSD (local storage)
  - `r32` is `Global attribute offset`
  - `r33` is `Workgroup size`
  - `r34` is `Job offset X`
  - `r35` is `Job offset Y`
  - `r36` is `Job offset Z`
  - `r37` is `Job size X`
  - `r38` is `Job size Y`
  - `r39` is `Job size Z`

## Command Buffer

- a `panvk_cmd_buffer` has
  - a `panvk_cmd_graphics_state`
  - a `panvk_cmd_compute_state`
  - a `panvk_push_constant_state`
    - this is user push consts
    - sysvals are also pushed on top of user push consts
  - a per-subqueue `panvk_cs_state`
  - a `panvk_tls_state`
    - tls is for shader reg spills, etc.
- subqueue progress
  - `init_subqueue` inits `syncobjs[subqueue].seqno` to 1
  - when an action op (dispatch, draw, etc.) is emitted to a cmdbuf
    - there is a `cs_sync64_add` to increments the seqno after the action op
      completes
    - `cmdbuf->state.cs[subqueue].relative_sync_point` is also incremented
  - after a cmdbuf is recorded, `finish_cs` increments
    `cs_progress_seqno_reg()` by `relative_sync_point` for each subqueue
  - when `panvk_per_arch(CmdPipelineBarrier2)` emits a barrier,
    - there is a `cs_sync64_wait` to wait until
      `syncobjs[subqueue].seqno > cs_progress_seqno_reg() + relative_sync_point`
  - remember that cmdbuf recording and submission are separated
    - `syncobjs[subqueue].seqno` is the number of completed ops on the subqueue
      since initialization
    - `cs_progress_seqno_reg()` is the number of completed ops on the subqueue
      when the cmdbuf starts executing
    - `relative_sync_point` is the number of ops recorded in the cmdbuf so far
- compute pipeline
  - `panvk_per_arch(BeginCommandBuffer)`
  - `panvk_per_arch(CmdDispatchBase)`
    - `GENX(pan_emit_tls)`
    - emits to `PANVK_SUBQUEUE_COMPUTE`
    - `panvk_per_arch(cs_pick_iter_sb)`
    - `cs_run_compute`
    - update seqno
  - `panvk_per_arch(EndCommandBuffer)`
    - `emit_tls` emits to `cmdbuf->state.tls.desc.cpu`
    - `finish_cs` on all subqueues
      - it accumulates `relative_sync_point` to `cs_progress_seqno_reg()`
- graphics pipeline
  - `panvk_per_arch(BeginCommandBuffer)`
  - `panvk_per_arch(CmdBeginRendering)`
  - `panvk_cmd_draw`
    - `update_tls`
    - `get_tiler_desc` inits `cmdbuf->state.gfx.render.tiler`
    - `get_fb_descs` inits `cmdbuf->state.gfx.render.fbds`
    - emits to `PANVK_SUBQUEUE_VERTEX_TILER`
  - `panvk_per_arch(CmdEndRendering)`
    - if there is no draw, `get_tiler_desc` and `get_fb_descs` haven't been
      called yet
      - if there is clear, `get_fb_descs` is called now
    - `flush_tiling`
      - `cs_finish_tiling` flushes tiling ops
      - `LOAD scrach01, [subq->ctx + syncobjs]` to load syncobj
      - `LOAD scrach2, [subq->ctx + iter_sb]`
      - `cs_heap_operation`
      - `cs_sync64_add` to increment syncobj
      - `STORE scratch2 [subq->ctx + syncobjs]` to store syncobj
    - `issue_fragment_jobs`
      - `wait_finish_tiling`
        - `cs_sync64_wait` until `[scratch01]` is greater than
          `progress_reg + relative_sync_point`
    - `resolve_attachments`
  - `panvk_per_arch(EndCommandBuffer)`
- `panvk_per_arch(CmdPipelineBarrier2)`
  - `panvk_per_arch(cmd_flush_draws)`
    - `flush_tiling`
    - `issue_fragment_jobs`
    - `force_fb_preload`
  - it looks at `wait_sb_mask` for each subqueue
    - `cs_wait_slots` to wait for scoreboard slots
    - if cache flush, `cs_flush_caches` and `cs_wait_slot`
    - if another subqueue waits on this subqueue, `cs_sync64_add`
  - it looks at `wait_subqueue_mask` for each subqueue, and if subqueue j is
    on `wait_subqueue_mask` of subqueue i,
    - `cs_sync64_wait` such that subqueue i waits for subqueue j
- scoreboard slots
  - slot 0 is for `PANVK_SB_LS` and `PANVK_SB_IMM_FLUSH`
  - slot 1 is for `PANVK_SB_DEFERRED_SYNC`
  - slot 2 is for `PANVK_SB_DEFERRED_FLUSH`
  - slot 3..7 are for iterators
    - each subqueue initializes `iter_sb` to 0
    - `panvk_per_arch(cs_pick_iter_sb)` picks `iter_sb`
    - `cs_match(b, iter_sb, cmp_scratch)` increments `iter_sb`
  - `panvk_per_arch(cs_pick_iter_sb)`
    - `LOAD scratch0, [subctx->iter_sb]`
    - `WAIT scratch0`
    - `SET_SB_ENTRY scratch0, LS`

## Command Buffer Example

- assume this call sequence to clear a color image
  - `vkBeginCommandBuffer` to begin cmd
  - `vkCmdPipelineBarrier` to transition an image from undef to xfer dst
    - src: `VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT`, no access
    - dst: `VK_PIPELINE_STAGE_TRANSFER_BIT`, `VK_ACCESS_TRANSFER_WRITE_BIT`
  - `vkCmdClearColorImage` to clear the image
  - `vkCmdPipelineBarrier` to transition the image to general
    - src: `VK_PIPELINE_STAGE_TRANSFER_BIT`, `VK_ACCESS_TRANSFER_WRITE_BIT`
    - dst: `VK_PIPELINE_STAGE_HOST_BIT`, `VK_ACCESS_HOST_READ_BIT`
  - `vkEndCommandBuffer` to end cmd
- first `panvk_per_arch(CmdPipelineBarrier2)` emits no instrs to any of the
  subqueue
- `panvk_per_arch(CmdClearColorImage)` emits instrs to
  `PANVK_SUBQUEUE_VERTEX_TILER`
  - `panvk_per_arch(cmd_meta_gfx_start)`
  - `vk_meta_clear_color_image`
    - `vk_meta_create_image_view`
    - `panvk_per_arch(CmdBeginRendering)`
    - `vk_meta_clear_attachments`
      - `vk_meta_create_pipeline_layout`
      - `vk_meta_create_graphics_pipeline`
      - `vk_common_CmdBindPipeline` binds the clear pipeline
      - `panvk_per_arch(CmdPushConstants2KHR)` pushes the clear value
      - `vk_meta_draw_rects`
        - `vk_common_CmdSetViewport`
        - `vk_common_CmdSetScissor`
        - `vk_meta_create_buffer`
        - `panvk_meta_cmd_bind_map_buffer`
        - `panvk_per_arch(CmdDraw)`
    - `panvk_per_arch(CmdEndRendering)`
  - `panvk_per_arch(cmd_meta_gfx_end)`
- looking at `panvk_per_arch(CmdDraw)` alone,
  - `update_tls`
    - allocs `MALI_LOCAL_STORAGE` and writes va to `d24`
  - `get_tiler_desc`
    - allocs `MALI_TILER_CONTEXT`, inits it, and writes va to `d40`
    - loads `tiler_heap` and `geom_buf` from subq ctx to scratches and stores
      them to `MALI_TILER_CONTEXT`
    - zeros bottom half of `MALI_TILER_CONTEXT`
    - `panvk_per_arch(cs_pick_iter_sb)` to pick the iter sb
    - `cs_heap_operation(MALI_CS_HEAP_OPERATION_VERTEX_TILER_STARTED)`
  - `get_fb_descs` allocs fb descs
    - `MALI_FRAMEBUFFER`
    - `MALI_ZS_CRC_EXTENSION`
    - one or more `MALI_RENDER_TARGET`
  - `panvk_per_arch(cmd_prepare_push_descs)`
  - `prepare_sysvals`
  - `prepare_push_uniforms`
    - `panvk_per_arch(cmd_prepare_push_uniforms)` allocs and inits push consts
      - first half is user push consts
      - second half is sysvals
    - push const va is written to `d8` and `d12`
      - push const is called FAU, fast access uniform
  - `prepare_vs`
    - `prepare_vs_driver_set` allocs and inits vs driver set
      - `MALI_ATTRIBUTE` for vs attrs
      - dummy `MALI_SAMPLER`
      - `panvk_per_arch(cmd_fill_dyn_bufs)` for `MALI_BUFFER`
      - more `MALI_BUFFER` for vbs
    - `panvk_per_arch(cmd_prepare_shader_res_table)`
      - `MALI_RESOURCE` array for the driver set and the user desc sets
    - writes res table va to `d0`
    - writes pos shader va to `d16`
    - no varying shader and no write to `d18`
  - `prepare_fs`
    - `prepare_fs_driver_set` allocs and inits vs driver set
      - dummy `MALI_SAMPLER`
      - `panvk_per_arch(cmd_fill_dyn_bufs)` for `MALI_BUFFER`
    - `panvk_per_arch(cmd_prepare_shader_res_table)`
      - `MALI_RESOURCE` array for the driver set and the user desc sets
    - writes res table va to `d4`
    - writes frag shader va to `d20`
  - writes draw info to `r32` to `r39`
    - vertex base, vertex count, instance count, index offset, etc.
  - no ib and no write to `d54`
  - writes to `r56` and `r48`
  - `prepare_blend`
    - allocs and inits `MALI_BLEND`
    - `panvk_per_arch(blend_emit_descs)`
    - writes blend va to `d50`
  - `prepare_ds`
    - allocs and inits `MALI_DEPTH_STENCIL`
    - writes ds va to `d52`
  - `prepare_dcd`
    - writes `MALI_DCD_FLAGS_0` to `r57`
      - kill pixel, front face ccw, cull front/back, msaa, etc.
    - writes `MALI_DCD_FLAGS_1` to `r58`
      - sample mask, color write mask, etc.
  - `prepare_vp`
    - writes `MALI_SCISSOR` to `d42`
    - writes viewport min/max depth to `r44` and `r45`
  - `cs_req_res(CS_IDVS_RES)`
  - `cs_run_idvs`
  - `cs_req_res(0)`
- looking at `panvk_per_arch(CmdEndRendering)` alone,
  - `flush_tiling` emits to `PANVK_SUBQUEUE_VERTEX_TILER`
    - `cs_req_res(CS_TILER_RES)`
    - `cs_finish_tiling`
    - `cs_req_res(0)`
    - `cs_heap_operation(MALI_CS_HEAP_OPERATION_VERTEX_TILER_COMPLETED)`
    - `cs_sync64_add` to increment seqno
    - increment `subq->iter_sb`
  - `issue_fragment_jobs` emits to `PANVK_SUBQUEUE_FRAGMENT`
    - `wait_finish_tiling`
      - `cs_sync64_wait` for `cs_sync64_add` in `flush_tiling`
        - that is, wait for `flush_tiling`
    - `panvk_per_arch(cs_pick_iter_sb)` to pick the iter sb
    - writes fb size to `r42` to `r43`
    - `prepare_fb_desc`
      - `GENX(pan_preload_fb)`
      - `GENX(pan_emit_fbd)`
        - `MALI_FRAMEBUFFER`
        - `MALI_ZS_CRC_EXTENSION`
        - `MALI_ZS_CRC_EXTENSION`
    - writes fbd va to `d48`
    - writes tiler ctx va to `d50`
    - writes layer count to `r47`
    - for each layer
      - patches tiler ctx va into fbd
      - writes fbd va and fbd flags to `d40`
      - `cs_req_res(CS_FRAG_RES)`
      - `cs_run_fragment`
      - `cs_req_res(0)`
      - increments fbd va
      - decrements layout count
    - `cs_finish_fragment`
    - `cs_sync64_add` to increment seqno
  - `resolve_attachments`
- second `panvk_per_arch(CmdPipelineBarrier2)` emits instrs to all subqueues
  - `collect_cs_deps`
    - because `VK_PIPELINE_STAGE_TRANSFER_BIT` is possible on
      `PANVK_SUBQUEUE_FRAGMENT` and `PANVK_SUBQUEUE_COMPUTE`
      - `deps->src[i].wait_sb_mask` has all iterator slots on both of them
      - `deps->src[i].cache_flush` has `MALI_CS_FLUSH_MODE_CLEAN` and
        `MALI_CS_FLUSH_MODE_CLEAN` on both of them
    - no `deps->dst[i].wait_subqueue_mask`
  - only `cs_wait_slots` and `cs_flush_caches` on the relevant subqueues
  - no `cs_sync64_wait` (for cross-subqueue sync) necessary
- `panvk_per_arch(EndCommandBuffer)` emits instrs to all subqueues
  - `finish_cs`
    - if there is any op in a subqueue, `cs_progress_seqno_reg` is updated
    - all scoreboard slots are waited and all caches are flushed
- how about `panvk_per_arch(CmdDispatchBase)`?
  - allocs `MALI_LOCAL_STORAGE`
  - `GENX(pan_emit_tls)` inits `MALI_LOCAL_STORAGE`
  - `panvk_per_arch(cmd_prepare_push_descs)`
  - `prepare_driver_set`
  - `prepare_push_uniforms`
  - `panvk_per_arch(cmd_prepare_shader_res_table)`
  - `cs_update_compute_ctx`
    - writes res table va to `d0`
    - writes push const (fau) va to `d8`
    - writes shader va to `d16`
    - writes tsd va to `d24`
    - writes 0 to `r32`
    - writes wg info to `r33` to `r39`
      - wg size, offsets, counts
  - `panvk_per_arch(cs_pick_iter_sb)`
  - `cs_req_res(CS_COMPUTE_RES)`
  - `cs_run_compute`
  - `cs_req_res(0)`
  - `cs_sync64_add` to increment seqno
  - increment `subq->iter_sb`

## Common Shader States

- all `RUN_*` instrs use 4 common shader states
  - SRT, specified in `d0`, `d2`, `d4`, `d6`
  - FAU, specified in `d8`, `d10`, `d12`, `d14`
  - SPD, specified in `d16`, `d18`, `d20`, `d22`
  - TSD, specified in `d24`, `d26`, `d28`, `d30`
- an SRT, shader resource table, is an array of `MALI_RESOURCE`
  - each `MALI_RESOURCE` corresponds to a descriptor set
    - it has an `address` field that points to an array of 32-byte descriptors
  - `panvk_cmd_draw`
    - `prepare_vs`
      - `prepare_vs_driver_set` allocs and inits a per-draw descriptor set
        - the set has `MAX_VS_ATTRIBS + 1 + vs->desc_info.dyn_bufs.count + vb_count`
          descriptors
        - `emit_vs_attrib` inits `MALI_ATTRIBUTE` descriptors
        - a dummy `MALI_SAMPLER` descriptor
        - `panvk_per_arch(cmd_fill_dyn_bufs)` inits `MALI_BUFFER` descriptors
          for dynamic ubos/ssbos
          - it extracts the buffer descriptors from the bound descriptor sets
            and patches in the dynamic offsets
      - `panvk_per_arch(cmd_prepare_shader_res_table)`
        - it allocs an array of `MALI_RESOURCE`s, one for each descriptor set
          (including the per-draw one)
        - the first res points to the per-draw descriptor set
        - the rest points to the user descriptor sets
      - the va of the resource array (and the array size) is written to `d0`
    - `prepare_fs`
      - `prepare_fs_driver_set` allocs and inits a per-draw descriptor set
        - the set has `1 + fs->desc_info.dyn_bufs.count` descriptors
        - a dummy `MALI_SAMPLER` descriptor
        - `panvk_per_arch(cmd_fill_dyn_bufs)` inits `MALI_BUFFER` descriptors
          for dynamic ubos/ssbos
      - `panvk_per_arch(cmd_prepare_shader_res_table)`
      - the va of the resource array (and the array size) is written to `d4`
  - `panvk_per_arch(CmdDispatchBase)`
    - `prepare_driver_set` allocs and inits a per-dispatch descriptor set
      - the first descriptor is a dummy `MALI_SAMPLER`
      - `panvk_per_arch(cmd_fill_dyn_bufs)` fills in the rest for dynamic
        ubos/ssbos
    - `panvk_per_arch(cmd_prepare_shader_res_table)`
    - the va of the resource array (and the array size) is written to `d0`
- a FAU is a Fast Access Uniform
  - each `panvk_cmd_draw` calls `prepare_push_uniforms` to prep push consts
    - `panvk_per_arch(cmd_prepare_push_uniforms)` always allocs 512 bytes
      - the first 256 bytes are for user push consts
      - the second 256 bytes are for sysvals
    - the va (and the size) is written to `d8` (for vs) and `d12` (for fs)
  - each `panvk_per_arch(CmdDispatchBase)` calls a different
    `prepare_push_uniforms` to prep push consts
    - `panvk_per_arch(cmd_prepare_push_uniforms)` always allocs 512 bytes
    - the va (and the size) is written to `d8`
- an SPD is a `MALI_SHADER_PROGRAM`
  - `panvk_shader_upload`
    - it uploads the binary to the exec mempool
    - it allocs `MALI_SHADER_PROGRAM`
      - one for fs/cs; multiple for vs
  - each `panvk_cmd_draw` calls `prepare_vs` and `prepare_fs`
    - they write `d16`, `d18`, and `d20` to point to the spds
  - each `panvk_per_arch(CmdDispatchBase)` writes `d16` to point to the spd
- a TSD is a `MALI_LOCAL_STORAGE`
  - TLS is thread local storage
    - it is used for register spills, and its size is calculated as
      `max(shader_spill_sizes) * thread_per_core * core_count`
  - WLS is workgroup local storage?
    - it is used for glsl `shared`, cl `__local`, spirv `Workgroup` storage
  - each `panvk_cmd_draw` calls `update_tls`
    - it allocs `cmdbuf->state.tls.desc` and writes `d24` on demand
      - both `RUN_IDVS` and `RUN_FRAGMENT` use `d24` for vs and fs
    - it updates `cmdbuf->state.tls.info.tls.size`
  - each `panvk_per_arch(CmdDispatchBase)` updates TSD
    - it allocs `cmdbuf->state.tls.desc`
    - it updates `cmdbuf->state.tls.info.tls.size`
    - unlike draws, each dispatch has its own `MALI_LOCAL_STORAGE`
      - this is because each dispatch might need its own WLS
      - but it still shares the per-cmdbuf TLS storage, which is not allocated
        yet and requires additional setup
  - `panvk_per_arch(EndCommandBuffer)` calls `emit_tls`
    - it allocs the per-cmdbuf tls storage of size
      `cmdbuf->state.tls.info.tls.size`
      - this is shared by gfx and comp pipelines
    - it calls `GENX(pan_emit_tls)` to init `cmdbuf->state.tls.desc`
      - this is only used by gfx pipelines

## `RUN_IDVS`

- `MALI_CS_RUN_IDVS`
  - `flags_override`
  - `progress_increment`
  - `malloc_enable`
  - `draw_id_register_enable`
  - `varying_srt_select` selects `d2` instead of `d0`
  - `varying_fau_select` selects `d10` instead of `d8`
  - `varying_tsd_select` selects `d26` instead of `d24`
  - `fragment_srt_select` selects `d4` instead of `d0`
  - `fragment_tsd_select` selects `d28` instead of `d24`
  - `draw_id`
  - `opcode` is `MALI_CS_OPCODE_RUN_IDVS`
- registers
  - `d0`, `d2`, `d4`, `d6`: SRT
  - `d8`, `d10`, `d12`, `d14`: FAU
  - `d16`, `d18`, `d20`, `d22`: SPD
  - `d24`, `d26`, `d28`, `d30`: TSD
  - `r32`: `Global attribute offset`
  - `r33`: `Index count`
  - `r34`: `Instance count`
  - `r35`: `Index offset`
  - `r36`: `Vertex offset`
  - `r37`: `Instance offset`
  - `r38`: `Tiler DCD flags2`
  - `r39`: `Index array size`
  - `d40`: `MALI_TILER_CONTEXT`
  - `d42`: `MALI_SCISSOR`
  - `r44`: `Low depth clamp`
  - `r45`: `High depth clamp`
  - `d46`: `Occlusion`
  - `d48`: `Varying allocation`
  - `d50`: `Blend`
  - `d52`: `Depth/stencil`
  - `d54`: `Indices`
  - `d56`: `MALI_PRIMITIVE_FLAGS`
  - `r57`: `MALI_DCD_FLAGS_0`
  - `r58`: `MALI_DCD_FLAGS_1`
  - `r60`: `MALI_PRIMITIVE_SIZE`
- `MALI_TILER_CONTEXT`
  - `polygon_list`
  - `hierarchy_mask`
  - `sample_pattern`
  - `sample_test_disable`
  - `first_provoking_vertex`
  - `fb_width`
  - `fb_height`
  - `layer_count`
  - `layer_offset`
  - `heap`
  - `geometry_buffer_size`
  - `geometry_buffer`
  - `completed_top`
  - `completed_bottom`
  - `private_state`

## `RUN_FRAGMENT`

- `MALI_CS_RUN_FRAGMENT`
  - `enable_tem`
  - `tile_order`
  - `progress_increment`
  - `opcode` is `MALI_CS_OPCODE_RUN_FRAGMENT`
- registers
  - `d40`: `MALI_FRAMEBUFFER_POINTER`
  - `d42`: `MALI_SCISSOR`
- `MALI_FRAMEBUFFER_PARAMETERS`
- `MALI_FRAMEBUFFER_PADDING`
- `MALI_ZS_CRC_EXTENSION`
- `MALI_RENDER_TARGET`

## `RUN_COMPUTE`

- `MALI_CS_RUN_COMPUTE`
  - `task_increment`
  - `task_axis`
  - `progress_increment`
  - `srt_select` selects one of the four SRT regs
  - `spd_select` selects one of the four SPD regs
  - `tsd_select` selects one of the four TSD regs
  - `fau_select` selects one of the four FAU regs
  - `opcode` is `MALI_CS_OPCODE_RUN_COMPUTE`
- registers
  - `d0`, `d2`, `d4`, `d6`: SRT
  - `d8`, `d10`, `d12`, `d14`: FAU
  - `d16`, `d18`, `d20`, `d22`: SPD
  - `d24`, `d26`, `d28`, `d30`: TSD
  - `r32`: `Global attribute offset`
  - `r33`: `MALI_COMPUTE_SIZE_WORKGROUP`
  - `r34`: `Job offset X`
  - `r35`: `Job offset Y`
  - `r36`: `Job offset Z`
  - `r37`: `Job size X`
  - `r38`: `Job size Y`
  - `r39`: `Job size Z`

## Tile Size, Load, Store, Blend

- `panvk_per_arch(CmdBeginRendering)`
  - `panvk_cmd_begin_rendering_init_state` handles load/store ops
    - `VK_ATTACHMENT_LOAD_OP_LOAD` becomes `preload`
    - `VK_ATTACHMENT_LOAD_OP_CLEAR` becomes `clear`
    - it ignores store ops and assumes `VK_ATTACHMENT_STORE_OP_STORE`
- `panvk_per_arch(CmdEndRendering)`
  - `issue_fragment_jobs` calls `prepare_fb_desc`
    - `GENX(pan_preload_fb)`
      - it allocs and inits pre-frame dcds, which are an array of 3
        `MALI_DRAW`
      - each `MALI_DRAW` runs a dcd pipeline, which is like a fs
      - `fb->bifrost.pre_post.modes[0]` is for rt preload and is
        `MALI_PRE_POST_FRAME_SHADER_MODE_ALWAYS`
      - `fb->bifrost.pre_post.modes[1]` is for zs preload and is
        `MALI_PRE_POST_FRAME_SHADER_MODE_EARLY_ZS_ALWAYS`
    - `GENX(pan_emit_fbd)`
      - it picks the tile size
        - 16x16 or smaller
      - `MALI_FRAMEBUFFER`
        - `cfg.pre_frame_0` is for rt preload
        - `cfg.pre_frame_1` is for zs preload
        - `cfg.post_frame` is disabled
        - `cfg.frame_shader_dcds` is the dcd shaders
      - `MALI_ZS_CRC_EXTENSION`
        - `ext->{zs,s}_writeback_base` is the writeback (store) offset
        - `ext->{zs,s}_writeback_row_stride` is the row stride
        - `ext->{zs,s}_writeback_surface_stride` is the surf stride
        - `ext->{zs,s}_write_format` is the format
        - `ext->{zs,s}_block_format` is the tiling
      - `MALI_RENDER_TARGET`
        - `cfg->rgb.base` is the writeback (store) offset
        - `cfg->rgb.row_stride` is the row stride
        - `cfg->rgb.surface_stride` is the surf stride
        - `cfg->writeback_format` is the format
        - `cfg->writeback_block_format` is the tiling
- `panvk_cmd_draw` calls `prepare_blend`
  - it allocs an array of `MALI_BLEND`
  - `panvk_per_arch(blend_emit_descs)` inits the array
    - `blend_needs_shader` determines if an rt needs a blend shader
      - a blend shader is needed when there is no fixed-func support, such as
        logicop, not-blendable formats, etc.
    - `GENX(pan_blend_create_shader)` creates the nir shader
    - `cfg.internal.mode` is the blend mode
      - `MALI_BLEND_MODE_OFF`, no rt or no color mask
      - `MALI_BLEND_MODE_OPAQUE`, opaque color (no blending)
      - `MALI_BLEND_MODE_FIXED_FUNCTION`, fixed-func blending
      - `MALI_BLEND_MODE_SHADER`, blend shader
  - the array va and size are written to `d50`
