Kernel Boot on x86-64
=====================

## `boot/compressed/`

- `vmlinux` in the root directory is objcopy'ed to `boot/compressed/` as
  `$(obj)/vmlinux.bin`, and is stripped
- `$(obj)/vmlinux.bin` is gzipped as `$(obj)/vmlinux.bin.gz`.
- generate `piggy.S` that `.incbin $(obj)/vmlinux.bin.gz` with the help of
  `mkpiggy`
- `piggy.S` and other sources under the directory are compiled into
  `$(obj)/vmlinux` (not the one in the root directory), using
  `$(obj)/vmlinux.lds`.

## `boot/`

- `$(obj)/compressed/vmlinux` is objcopy'ed here as `$(obj)/vmlinux.bin`.
- `setup.elf` is compiled from sources under this directory, using `setup.ld`.
- `setup.elf` is stripped as `setup.bin`
- `setup.bin` and `vmlinux.bin` are put together by `tools/build` to create
  `bzImage`.
  - `build` patches the header to give correct values.

## `CONFIG_EFI_STUB`

- `efi_pe_entry` of `x86-stub.c` is the entrypoint
  - `LOADED_IMAGE_PROTOCOL` is used to get `efi_loaded_image_t` from the
    bootloader
  - `boot_params` is allcoated and initialized from `efi_loaded_image_t`
  - `efi_stub_entry` jumps to the kernel image
    - `efi_decompress_kernel` self-decompresses
    - `efi_load_initrd` loads initramfs
    - `enter_kernel` jumps to the entrypoint
      - `%rsi` holds `boot_params`
- `SYM_CODE_START_NOALIGN(startup_64)` is the entrypoint
  - `%rsi` holds `boot_params`
  - `__startup_64`
  - it jumps to `common_startup_64` at the end
- `SYM_INNER_LABEL(common_startup_64, SYM_L_LOCAL)`
  - `early_setup_idt`
  - it calls `x86_64_start_kernel` at the end
- `x86_64_start_kernel`
  - `copy_bootdata` copies `boot_params`
    - it also copies cmdline to `boot_command_line`
  - it calls `start_kernel` at the end
    - `setup_arch` calls `reserve_initrd` to init `initrd_start` and
      `initrd_end`

## Bootloader

- `Document/x86/boot.rst`
- Bootloader loads first some KB of the kernel to a place it chooses.
  - It contains the header and real-mode code.
- Bootloader also loads protect-mode code to the right place.
  - The right place is given by `code32_start` of the header
  - It is usually in the high memory, which is not accessible in real mode
  - So the bootloader might either enter protected mode
  - Or, use `Int 15/AH=87h`, <http://www.ctyme.com/intr/rb-1527.htm>
- It then jumps to the start of the header.

## 16-bit Real-Mode

- It starts from `boot/header.S`.  The first two bytes of the header is a jump
  instruction.  It jumps to `start_of_setup`, to call `main` in `boot/main.c`.
- `protected_mode_jump` called by `go_to_protected_mode` enters the 32-bit
  protected mode and jumps to the start of protected-mode code at
  `code32_start`

## 32-bit Protected Mode and 64-bit Long Mode

- It usually starts from `startup_32` in `boot/compressed/head_64.S`
  - it sets up identity page tables, enables paging, enters long mode
    (64-bit mode), and jumps to `startup_64`
- `startup_64` decompresses the kernel
  - The compressed kernel is loaded at `code32_start` by current bootloader,
    which is hardcoded at `0x100000`.  Future bootloader should load it to
    `pref_address`, which is `LOAD_PHYSICAL_ADDR`.
  - The decompressor wants to decompress it to `LOAD_PHYSICAL_ADDR` for
    non-relocatable kernel or decompress in-place for relocatable kernel.
  - The decompressed kernel is an elf image.  It is parsed and its elf programs
    are copied in-place to the right place.
  - It has in `ebp` the loaded address (`code32_start` or `pref_address`) and in
    `ebx` the `LOAD_PHYSICAL_ADDR` (usually the same, 0x1000000 since 2.6.31).
    The size difference between the uncompressed/compressed images plus
    necessary decompress offset is in `z_extract_offset`.
  - It copies the compressed kernel from loaded address to physical address
    (`ebx`).  It is copied backward to allow in-place copy.  It is copied to the
    end of physical address to allow in-place decompressions.
- finally, it jumps to another `startup_64` in `kernel/head_64.S`
  - with identity-mapped address space
  - the stack is set up by `movq initial_stack(%rip), %esp`
  - jumps to `x86_64_start_kernel`, which calls `start_kernel`.

## Timers

- TSC and LAPIC timers
  - TSC frequency is cpu clock frequency
  - `RDTSC` has the current counter value
  - LAPIC timers are per-core timers that fire when TSC exceeds the programmed
    values
    - this is the TSC-deadline mode
    - LAPIC timers support other modes
- HPET
  - designed to replace PIT
- ACPI timer
  - do not use
- PIT timer
  - do not use
  - may be emulated by HPET
- RTC timer
  - do not use

## Kernel

- Linux x86 boot protocol is defined in `Documentation/x86/boot.rst`
  - the bootloader should load the kernel to certain memory addresses
  - the first sector of the kernel is used for communications between the
    bootloader and the kernel: how big is the kernel?  where did the bootloader
    write the commandline to?  where was the initramfs loaded?
- After arch specific early boot code, `start_kernel` in `init/main.c` is called.
  - it prints a "Linux version" banner
  - it calls `setup_arch`
  - it spawns a thread to run `kernel_init`
    - the thread is the first and has pid 1
    - it will later `do_execve("/sbin/init")`
- see <../init.md>

## Resources

- `/proc/iomem`
- During `setup_arch`, `e820__reserve_resources` is called to turn
  non-reserved e820 entries into resources.
  - Incidentally, `e820__setup_pci_gap` decides `pci_mem_start`, which finds a gap
    between e820 entries that is high and large enough.
- In subsys initcalls, `pcibios_init` is called.  It calls
  `pcibios_resource_survey` to allocate PCI resources.  That calls
  `e820__reserve_resources_late` to insert the rest of e820 entries.

## IDT Initialization

- in real mode, the cpu uses Interrupt Vector Table (IVT)
- in protected mode or long mode, the cpu uses Interrupt Descriptor Table
  (IDT)
- IDT entry size is 256 with the first 32 entries reserved for processor
  exceptions (traps)
  - `IDT_ENTRIES` and `NR_VECTORS` is 256
  - `NUM_EXCEPTION_VECTORS` and `FIRST_EXTERNAL_VECTOR` is 32
  - traps include
    - `X86_TRAP_DE` divide-by-zero
    - `X86_TRAP_NMI` NMI
    - `X86_TRAP_OF` overflow
    - `X86_TRAP_PF` page fault
    - and others
- `NR_IRQS` is `NR_VECTORS + IO_APIC_VECTOR_LIMIT`
  - `FIRST_SYSTEM_VECTOR` is `LOCAL_TIMER_VECTOR` which is 0xec
- In `go_to_protected_mode`,
  - `realmode_switch_hook` issues `cli` to disable local irq
  - `mask_all_interrupts` masks out all irq in PIC
  - `setup_idt` loads a null IDT
  - jumps to protect mode and call `startup_32`
- In `startup_32` in `boot/compressed/head_64.S`,
  - it jumps to long mode (64-bit) and call `startup_64`
- In `startup_64` in `boot/compressed/head_64.S`,
  - `load_stage1_idt` loads `boot_idt` which is still all zeros
  - `load_stage2_idt` initializes `X86_TRAP_PF` to `boot_page_fault` which
    calls `do_boot_page_fault`
  - it extracts the kernel and jumps to another `startup_64`
- In `startup_64` in `kernel/head_64.S`,
  - `startup_64_setup_env` loads `bringup_idt_table` which is all zeros
  - `early_setup_idt` loads `bringup_idt_table` again after switching page
    table
  - it calls `x86_64_start_kernel`
- In `x86_64_start_kernel`,
  - `idt_setup_early_handler` loads `idt_table`
    - `idt_table` is initialized from `early_idt_handler_array`, where all
      traps are handled by `early_idt_handler_common` that sets up early
      pgtable and works around bugs
  - at the end, `start_kernel` is called
- In `setup_arch` called by `start_kernel`,
  - `idt_setup_early_traps` updates some trap handlers in `idt_table`
  - `idt_setup_early_pf` updated `X86_TRAP_PF` handler
- In `trap_init` called by `start_kernel`,
  - `idt_setup_traps` sets the final trap handlers
- In `start_kernel` after `trap_init`,
  - `early_irq_init` initializes the kernel IRQ subsystem and calls
    `arch_early_irq_init`
  - `init_IRQ` initializes all HW IRQs after traps.
    - `x86_init.irqs.intr_init` points to `native_init_IRQ`
    - `idt_setup_apic_and_irq_gates` initializes that part of IDT from
      `irq_entries_start` whose handlers are all `asm_common_interrupt`
      - `DECLARE_IDTENTRY_IRQ(X86_TRAP_OTHER, common_interrupt)` expands to
        `idtentry_irq` which defines `asm_common_interrupt`
      - it calls `common_interrupt` which calls `generic_handle_irq_desc`
  - `local_irq_enable` is called

## Context Switches

- current task
  - `current` is defined to `get_current`
  - it returns `current_task` per-cpu variable
- task switch
  - `switch_to` is defined to `__switch_to_asm`
  - saves `prev` registers to `prev` stack
  - switches to `next` stack
  - restores `next` registers from `next` stack
  - `__switch_to`
    - sets `current_task` to `next_p`
    - sets `cpu_current_top_of_stack` to `task_top_of_stack(next_p)`
    - others
  - because the stack has been switched, when we return from `__switch_to`, we
    return to the last frame of `next`
- new task
  - other than `init_task`, all tasks are created by `copy_process`
  - `copy_process` calls the arch-specific `copy_thread`
    - `copy_thread` sets `ret_addr` to `ret_from_fork`
    - after `__switch_to` switches to the new task, it will return to
      `ret_from_fork`
  - `ret_from_fork`
    - calls `schedule_tail` to set up the fresh new task
    - if `rbx` is set, this is a kernel thread and `rbx` is the starting
      function
      - this is set up in `copy_thread`
    - otherwise, this is a userspace task
      - `syscall_exit_to_user_mode` is generic code
      - `swapgs_restore_regs_and_return_to_usermode`
        - restores entry trampoline regs
        - switches to entry trampoline stack
        - restores IRET frame
        - `iretq`
- entry trampoline stack
  - the entry trampoline stack is the stack the kernel uses after entry from
    userspace or before exit to userspace
  - `cpu_init` calls `load_sp0` to set `sp0` to `cpu_entry_stack(cpu)`
    - it never changes after initialization
  - `cpu_init_exception_handling` sets TSS
    - some exceptions use `cea_exception_stacks` stacks
    - others just use `sp0`, that is, `cpu_entry_stack`
- context switch
  - `idtentry` is the macro that defines the entrypoint (`asm_foo`) for
    exception vectors
    - `error_entry` saves register to the current stack
      - if entering from kernel, this is kernel stack of the current task
      - if entering from userspace, this is trampoline stack of the current
        cpu
        - `sync_regs` copies the contents from the trampoline stack to the
          kernel stack of the current task and returns back to `asm_foo`

## External Interrupts

- when an external interrupt is received, CPU disables interrupts (`cli`) and
  pushes some flags registers to the stack automatically
  - it pushes `ss`, `rsp`, `rflags`, `cs`, and `rip` automatically
    - `iretq` will pop them back
  - it also pushes error code, aka hw irq number
  - `PUSH_AND_CLEAR_REGS` will push more regs
    - `rdi`, `rsi`, `rdx`, `rcx`, `rax`, `r8` to `r11`, `rbx`, `rbp`, `r12` to
      `r15`
  - together, the stack will contain `pt_regs`
- IDT entries from `FIRST_EXTERNAL_VECTOR` to `NR_VECTORS` are initialized
  from `irq_entries_start`
  - `DECLARE_IDTENTRY_IRQ(X86_TRAP_OTHER, common_interrupt)`
    - this expands to `idtentry_irq` which expands to `idtentry` which expands
      to `asm_common_interrupt` when expanded by the assembler
    - `error_entry` saves registers onto the kernel stack
  - `DEFINE_IDTENTRY_IRQ(common_interrupt)`
    - this defines `common_interrupt` and `__common_interrupt`
  - `asm_common_interrupt`, the handler, is defined by `idtentry_irq`
    - `error_entry`
      - `PUSH_AND_CLEAR_REGS` pushes registers to the current stack
        - it could be the entry trampoline stack or the kernel stack of
          `current`
      - `sync_regs` copies the saved registers to the kernel stack of `current`
      - `sync_regs` returns the kernel stack
    - switch the stack to the return value of `error_entry` which is always
      the kernel stack of `current`
    - call `common_interrupt`
  - `common_interrupt`
    - `irqentry_enter` is the generic entry enter code
    - `run_irq_on_irqstack_cond` calls `__common_interrupt` on either the
      kernel stack or on irqstack `pcpu_hot.hardirq_stack_ptr`
    - `irqentry_exit` is the generic entry exit code
  - `__common_interrupt`
    - look up `vector_irq[vector]` to get `struct irq_desc`
    - call `generic_handle_irq_desc` on the irq desc
- IRQ handling
  - `early_irq_init` sets up irq to `irq_desc` mappings
  - `idt_setup_apic_and_irq_gates` sets up IDT
  - `irq_set_chip_and_handler` updates an `irq_desc` to point to the specified
    `irq_chip` and handler
  - when a hw irq happens, `IDT -> common_interrupt -> irq_desc::handle_irq`
  - the handler acks the irq, and calls each action in the `irq_desc::action`
    list
  - `request_irq` registers an action to an `irq_desc`

## Syscalls

- `syscall_init` initializes
  - `MSR_STAR` to `(__USER32_CS << 16) | __KERNEL_CS)`
  - `MSR_LSTAR` to `entry_SYSCALL_64`
- when userspace executes `syscall` instr, the instr
  - saves `rip` to `rcx` and `rflags` to `r11`
  - loads `rip` from `MSR_LSTAR`
  - loads `cs` and `ss` from `MSR_STAR`
- calling convention
  - syscall num is in `rax`
  - arg 0..5 are in `rdi`, `rsi`, `rdx`, `r10`, `r8`, `r9`
    - because `syscall` saves return addr to `rcx`, it uses `r10` for arg 3,
      which is the only difference from C convention
- `entry_SYSCALL_64`
  - it switches to empty kernel stack
    - `movq PER_CPU_VAR(cpu_current_top_of_stack), %rsp`
  - it constructs `pt_reg` on kernel stack
    - unlike interrupts, it has to push some regs manually
    - `PUSH_AND_CLEAR_REGS` pushes the rest regs
  - `do_syscall_64`
    - `movq %rsp, %rdi` passes `pt_regs`
    - `movslq %eax, %rsi` passes syscall nr
    - `syscall_enter_from_user_mode`
      - this enables irq for kernel mode
    - it dispatches based on the generated `asm/syscalls_64.h`
    - `syscall_exit_to_user_mode`
      - this disables irq for user mode
  - it restores regs
    - `POP_REGS` restores regs saved by `PUSH_AND_CLEAR_REGS`
    - it switches to `TSS_sp0` trampoline stack
    - `pushq RSP-RDI(%rdi)` pushes `pt_regs->sp`
      - `rdi` points to `pt_regs->di`
      - `RSP - RDI` is the offset from `pt_regs->di` to `pt_regs->sp`
    - `pushq (%rdi)` pushes `pt_regs->di`
    - `SWITCH_TO_USER_CR3_STACK`
    - `popq %rdi` restores user `rdi`
    - `popq %rsp` restores user `rsp`, switching back to user stack
  - `sysretq` undoes `syscall`

## Interrupt Descriptor Table

- `asm/segment.h`
  - Interrupt Descriptor Table, IDT
    - there are 256 (`IDT_ENTRIES`) descriptors
    - the table is loaded with `lidt` instruction
    - each descriptor is 16 bytes
    - it describes when an interrupt happens, where to jump to (and the
      priviledge level, irq disable, whether to save context, etc.)
    - the jump targets are defined by `idtentry` in `entry_64.S`
- `asm/irq_vectors.h`
  - vectors
    - there are 256 (`NR_VECTORS`) vectors
    - vector 0..31 are for system traps and exceptions and are hardcoded by CPU
    - vector 32..127 are for device interrupts
      - `FIRST_EXTERNAL_VECTOR` is 32
      - `ISA_IRQ_VECTOR` uses 48..63 for ISA
      - these are initialized from `irq_entries_start` and call `do_IRQ` after
      	some setups
    - vector 128 is for legacy int80 syscall
      - `IA32_SYSCALL_VECTOR` is 128
    - vector 129..230ish is unused
    - the rest is for kernel-defined IPIs
      - starting from `FIRST_SYSTEM_VECTOR`

## Privilege

- In an IDT entry, there is a 16-bits segment selector and a 2-bits DPL.
  - The selector decides thew new segment
  - The DPL decides the lowest privilege that can interrupt
  - `cs` gives CPL.  If `CPL >= PL of new segment` and `CPL <= DPL`, interrupt
    succeeds.  The idea is so that the interrupt handler has higher privilege
    than the program caused the interrupt and the program has enough privilege
    to cause the interrupt.
  - `cs:eip` becomes `segment selector:offset` in the IDT entry.
- In `setup_gdt` in `boot/pm.c`, `GDT_ENTRY_BOOT_CS` and `GDT_ENTRY_BOOT_DS`
  GDT have acess flags `0x9b` and `0x93`.  Both indicate highest privilege.

## 32-bit kernel APM

- `arch/x86/kernel/apm_32.c`
- there is an apm thread polling the apm hw events.  If suspend or standy
  events are received, the kernel does the suspend/standby.
- there is `/proc/apm_bios` for userspace to check for apm status.
- emulation
  - emulate an apm bios on (arm) embedded system
  - depends on the PMU to provide `apm_get_power_status`
  - userspace can control suspend/standby too.

## AES-NI

- `CONFIG_CRYPTO_AES_NI_INTEL` enables AES-NI
- `aesni_init`
  - `crypto_register_alg` registers `aesni_cipher_alg`
    - `cra_name` is `aes`
    - `cra_driver_name` is `aes-aesni`
    - `cra_flags` is `CRYPTO_ALG_TYPE_CIPHER`
  - `simd_register_skciphers_compat` registers
    - `aesni_skciphers`
    - `aes_gcm_algs_aesni`
    - `aesni_xctr`
  - `register_avx_algs` registers more
- when a consumer calls `crypto_alloc_skcipher` with an algorithm name,
  `__crypto_alg_lookup` matches both `cra_name` and `cra_driver_name`
